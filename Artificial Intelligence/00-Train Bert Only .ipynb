{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "227108eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\YHLB2266\\Données\n",
      "[nltk_data]     d'applications\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\YHLB2266\\Données\n",
      "[nltk_data]     d'applications\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f918f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34453</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37760</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15243</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28007</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     doc  label\n",
       "34453   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "37760   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "15304   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "15243   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "28007   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Load data and set labels\n",
    "data_positive = pd.read_csv('data/positive.csv', header=None)\n",
    "column_labels = ['doc']\n",
    "data_positive.columns = column_labels\n",
    "data_positive['label'] = 1\n",
    "\n",
    "\n",
    "# Display 5 random samples\n",
    "data_positive.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeee3bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    doc  label\n",
       "302    NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0\n",
       "2043   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0\n",
       "1564   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0\n",
       "340    NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0\n",
       "2023   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_negative1 = pd.read_csv('data/negative-1.csv')\n",
    "data_negative1.columns = column_labels\n",
    "data_negative1['label'] = 0\n",
    "\n",
    "data_negative1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72de9476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>The finicky guinea negotiates formamide.The d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>The hungry synonym buzes medium.The dispensab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>The mammoth saucer fences jug.The fair bevera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>The aquatic designation protects eyebrows.The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>The flaky wilderness creates medium.The knott...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    doc  label\n",
       "1710   The finicky guinea negotiates formamide.The d...      0\n",
       "242    The hungry synonym buzes medium.The dispensab...      0\n",
       "2951   The mammoth saucer fences jug.The fair bevera...      0\n",
       "4255   The aquatic designation protects eyebrows.The...      0\n",
       "2452   The flaky wilderness creates medium.The knott...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_negative2 = pd.read_csv('data/negative-2.csv')\n",
    "data_negative2.columns = column_labels\n",
    "data_negative2['label'] = 0\n",
    "\n",
    "data_negative3 = pd.read_csv('data/negative-3.csv')\n",
    "data_negative3.columns = column_labels\n",
    "data_negative3['label'] = 0\n",
    " \n",
    "\n",
    "data_negative5 = pd.read_csv('data/negative-5.csv')\n",
    "data_negative5.columns = column_labels\n",
    "data_negative5['label'] = 0\n",
    "\n",
    "\n",
    "data_negative6 = pd.read_csv('data/negative-6.csv')\n",
    "data_negative6.columns = column_labels\n",
    "data_negative6['label'] = 0\n",
    "\n",
    "data_negative7 = pd.read_csv('data/negative-7.csv')\n",
    "data_negative7.columns = column_labels\n",
    "data_negative7['label'] = 0\n",
    "\n",
    "data_negative8 = pd.read_csv('data/negative-8.csv')\n",
    "data_negative8.columns = column_labels\n",
    "data_negative8['label'] = 0\n",
    "\n",
    "data_negative9 = pd.read_csv('data/negative-9.csv')\n",
    "data_negative9.columns = column_labels\n",
    "data_negative9['label'] = 0\n",
    "\n",
    "data_negative9.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b412b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate complaining and non-complaining data\n",
    "data = pd.concat([data_positive, data_negative1, data_negative2, data_negative3, data_negative5, data_negative6, data_negative7, data_negative8, data_negative9], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707dac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66137</th>\n",
       "      <td>PAR ORDONNANCE N° 88-092 DU 07 JUILLET 1998 ; ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61468</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66194</th>\n",
       "      <td>ET 193 ; VU, TEL QUE MODIFIE ET COMPLETE A CE ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63698</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     doc  label\n",
       "66137  PAR ORDONNANCE N° 88-092 DU 07 JUILLET 1998 ; ...      0\n",
       "61468   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0\n",
       "7003    NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "66194  ET 193 ; VU, TEL QUE MODIFIE ET COMPLETE A CE ...      0\n",
       "63698   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display 5 random samples\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a911a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ca0b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46871</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59220</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8898</th>\n",
       "      <td>VU LA LOI-CADRE N° 14/004 DU 11 FEVRIRER 2014 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     doc  label\n",
       "48838   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "46871  NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN D...      0\n",
       "59220   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      0\n",
       "59995   NOUS SOUSSIGNES, MEMBRES DU JURY DE L’EXAMEN ...      1\n",
       "8898   VU LA LOI-CADRE N° 14/004 DU 11 FEVRIRER 2014 ...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "528d0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e66775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Tokenization and removing stop words and punctuation\n",
    "stop_words = set(stopwords.words('french'))  # Assuming the documents are in French\n",
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b9eb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\YHLB2266\\Données\n",
      "[nltk_data]     d'applications\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\YHLB2266\\Données\n",
      "[nltk_data]     d'applications\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPooling1D, Bidirectional, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import np_utils\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPooling1D, Bidirectional, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Ensure you have the necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f4e531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the Doc\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and punctuation\n",
    "    return ' '.join([word for word in tokens if word not in stop_words and word not in punctuation])\n",
    "\n",
    "df['processed_doc'] = df['doc'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ae803ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_doc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9e15675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112250 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['processed_doc'])\n",
    "sequences = tokenizer.texts_to_sequences(df['processed_doc'])\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique tokens.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e417739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c47d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True) \n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "test_df.reset_index(drop=True, inplace=True) \n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.doc[index]\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        attention_mask = inputs['attention_mask'][0]\n",
    "        label = torch.tensor(self.data.label[index])\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Creating instances of training and validation set\n",
    "train_dataset = TextDataset(train_df, tokenizer)\n",
    "valid_dataset = TextDataset(test_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25adad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"./bert_finetuned_diploma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ff821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950d983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
